# hadoop

hadoop fs -ls /

hadoop fs -copyFromLocal local_fpath hdfs_fpath  #copy file from local to hdfs
hadoop fs -copyToLocal hdfs_fpath local_fpath  #copy file from hdfs to local

hadoop fs -rmr hdfs_fpath  # delete a hdfs folder



# hive
delete all rows in a table:
truncate table table_name;

set hive.cli.print.current.db=true  # show current database in command prompt

hive -i init_file  #start hive with an initialization file

hive -f query.hql
hive -e "selec * from table_name"

hive -S # suppress info messages

alter table old_table rename to new_table; # rename table

# delete all tables/views in a database
hive -e 'use db;show tables'|xargs -I '{}' hive -e 'use db;drop table {}'
hive -e 'use db;show tables'|xargs -I '{}' hive -e 'use db;drop view {}'

# set variables in hive scripts
hive> set CURRENT_DATE='2012-09-16';
hive> select * from foo where day >= '${hiveconf:CURRENT_DATE}'

similarly, you could pass on command line:
% hive -hiveconf CURRENT_DATE='2014-09-08' -f test.hql

To see all the available variables, from the command line, run
% hive -e 'set;'
or from the hive prompt, run
hive> set;

# load data in file to hive table
create table test (query) row format delimited fields terminated by ',' stored as textfile;
LOAD DATA [local] inpath 'data_file_path' [overwrite] into table test;

# use virtualenv in hive
http://www.florianwilhelm.info/2016/10/python_udf_in_hive/

